{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjE19j4itT2jbej6sJIItY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i2mmmmm/Study/blob/main/Pytorch/%EC%8B%A0%EA%B2%BD%EB%A7%9D%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **딥러닝에서 자주 사용되는 신경망 아키텍처**\n",
        "\n",
        "### 1. 다층 퍼셉트론 (Multilayer Perceptron, MLP)\n",
        "- 기본적인 신경망 구조\n",
        "- 여러 개의 은닉층을 포함하는 다층 구조\n",
        "- 활성화 함수, 출력층의 역할 등\n",
        "\n",
        "### 2. 합성곱 신경망 (Convolutional Neural Network, CNN)\n",
        "- 이미지 처리에 효과적인 아키텍처\n",
        "- 합성곱과 풀링 레이어의 개념\n",
        "- 전이 학습 (Transfer Learning)의 개요\n",
        "\n",
        "### 3. 순환 신경망 (Recurrent Neural Network, RNN)\n",
        "- 순차적인 데이터 처리에 적합한 아키텍처\n",
        "- 순환층의 동작과 장단기 메모리 (Long Short-Term Memory, LSTM)\n",
        "- 자연어 처리와 시계열 데이터에 활용 예제\n",
        "\n",
        "### 4. 오토인코더 (Autoencoder)\n",
        "- 비지도 학습을 위한 신경망 아키텍처\n",
        "- 인코더와 디코더의 역할\n",
        "- 데이터의 차원 축소와 생성에 사용되는 예제"
      ],
      "metadata": {
        "id": "cQ9CMB-YmSPE"
      }
    }
  ]
}