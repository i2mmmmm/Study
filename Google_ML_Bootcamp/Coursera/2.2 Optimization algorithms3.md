## 2.2 Optimization algorithms

### 3. momentum (gradient descent with momentum)

- Gradient descent 의 문제점이
  - 경사가 가파를수록 진동생겨서 느려지고
  - 학습률 높이면 발산할 수도 있고
  
  -> 그래서 momentum 을 도입
- momentum의 아이디어는 **기울기의 지수 가중 평균**을 구해서 그걸 이용해서 **가중을 업데이트** 하는 것
- 일반적인 경사 하강법에서는 dw, db를 사용하지만  
  모멘텀을 사용한 경사 하강법에서는 vdW, vdB를 사용
- 수직 방향의 진동을 줄여주고 수평 방향으로 빠르게 이동할 수 있게 돕는
- 밥그릇 모양의 함수에 공이 가운데로 굴러들어가는 듯
- 수식은
  - v<sub>dW</sub> = β v<sub>dW</sub> + (1-β) dW
  - v<sub>db</sub> = β v<sub>db</sub> + (1-β) db
    - 가중치 업데이트 (W = W - αv<sub>dW</sub>, b = b - αv<sub>db</sub>)
  - 하이퍼 파라미터는 α, β 두가지 인데 가장 흔한 β 값 = 0.9
    - = 최근 10일 간의 평균 기온 산출 = 지난 10개의 기울기 하강 평균치
    - 다른 β값 설정해봐도 되지만 0.9는 꽤 잘 작동하는 값
    - 바이어스 수정 : 10개 지나면 미분항 워밍업되어서 바이어스 추정치가 아니기 때문에  
      사람들이 바이어스 수정을 잘 신경쓰지 않는다.
- 문헌에서는 (1-β) 가 생략된 공식을 자주 본다. (개인적으로는 (1-β) 있는 것을 선호)     
   v<sub>dW</sub> = β v<sub>dW</sub> +dW  
   v<sub>db</sub> = β v<sub>db</sub> +db

### 4. RMSprop (Root Mean Square prop)
- 역시 강사 하강 속도를 높일 수 있는 방법
- 지수 가중 이동 평균을 사용해 기울기의 제곱을 계산하고 이를 바탕으로 가중치를 업데이트
- 수식
  - S<sub>dW</sub> = β S<sub>dW</sub> + (1−β) dW<sup>2</sup>
  - S<sub>db</sub> = β S<sub>db</sub> + (1−β) db<sup>2</sup>
  - 가중치 업데이트  
    ![image](https://github.com/user-attachments/assets/3d47b5fd-ea14-409c-943c-ac7a9fa4da1c)

    - ϵ은 수치적 안정성을 위해 추가된 아주 작은 값 (ex 10<sup>-8</sup>)
- 수직 방향(b 방향)에서 기울기가 크기 때문에 db<sup>2</sup> 값이 크며, S<sub>db</sub>도 커짐  
  수평 방향(w 방향)에서 기울기가 작기 때문에 dW<sup>2</sup>값이 작으며, S<sub>dW</sub>도 작음

- **수직** 방향 업데이트는 **큰 값**으로 나누니 **진동이 감소**하고  
  **수평** 방향 업데이트는 **작은 값**으로 나누어 **빠르게** 진행
- 학습률 α를 더 크게 설정할 수 있어 **빠른 학습**이 **가능**하다는 **장점**

 
### 5. ADAM optimization algorithm
- ADAM (adaptive moment estimation)
- ADAM = base(momentum) + RMSprop  
- V<sub>dw</sub> = 0,  S<sub>dw</sub> = 0  
  V<sub>db</sub> = 0,  S<sub>db</sub> = 0  
  초기화부터 

![image](https://github.com/user-attachments/assets/e9107155-4dc7-4023-89c8-161cc763f439)
이렇게 알고리즘 구현

- 하이퍼파라미터
  - α : 튜닝할 필요없이 다양한 값 시도하고 효과있는 거 찾기
  - β<sub>1</sub> : 대체로 0.9 (dW)
  - β<sub>2</sub> : 대체로 0.999 (dW<sup>2</sup>)
  - ε : 10<sup>-8</sup>
  - β<sub>1</sub>, β<sub>2</sub>, ε 세가지는 거의 대부분 그대로 사용하고 α 만 바꿔가면서 좋은 값 찾기
