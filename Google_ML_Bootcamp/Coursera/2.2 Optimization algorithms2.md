## 2.2 Optimization algorithms

### 2. Exponentially Weighted Averages (지수 가중 평균)

ex) data = 런던의 1년 날씨 매일 평균 기온
  **V<sub>0</sub> =0** 로 초기화해두고 **일자별**로 모두 **0.9배**에 해당 날짜 온도를 **0.1로 가중치**  
  V<sub>1</sub> = 0.9 V<sub>0</sub> + 0.1 θ<sub>1</sub>  <- (θ<sub>1</sub> = 첫째날의 온도)  
  V<sub>2</sub> = 0.9 V<sub>1</sub> + 0.1 θ<sub>2</sub>  
  V<sub>t</sub> = 0.9 V<sub>t-1</sub> + 0.1 θ<sub>t</sub>

![image](https://github.com/user-attachments/assets/9709385b-88a7-4fc2-82e3-b708959c569e)

- 모든 V들을 계산해서 그래프에 얹어보면 빨간색🔴 그래프  
  일별 날짜의 온도를 이동 평균값으로 나타낸 **지수 가중 평균**

- 공식화하면
  V<sub>t</sub> = β V<sub>t-1</sub> + (1-β) θ<sub>t</sub>

  1/1-β 를 계산해보면 몇 개 데이터의 평균인지가 나오는데  
  β = 0.9 ≈ 10 days temperture average  
  β = 0.98 -> 1/0.02 ≈ 50days

![image](https://github.com/user-attachments/assets/288f02f7-a846-4469-9dc1-bd6051faa3d0)

- 연두색🟢 그래프가 β = 0.98 일 때
  - β값이 커질수록 부드러운 그래프 생성 (이유는 평균값을 더 많은 일수로 구한 것이기 때문)
  - 하지만 시점 이후의 값들과의 평균을 낸거라서 그래프가 약간 오른쪽으로 이동하게 됨
- 노란색🟡 그래프가 β = 0.5 일 때 ( = 이틀 평균온도)
  - β값이 작아질수록 데이터는 시끄럽고, 이상치에 예민하게 반응

- 가중 평균 공식 역산하기  
V<sub>100</sub>=0.9 V<sub>99</sub> + 0.1 θ<sub>100</sub>  
	=0.1 θ<sub>100</sub> + 0.9 V<sub>99</sub>  
	=0.1 θ<sub>100</sub> + 0.9 (0.1 θ<sub>99</sub> +0.9 V<sub>98</sup>)  
	=0.1 θ<sub>100</sub> + 0.9 (0.1 θ<sup>99</sub> +0.9 ( 0.1 θ<sub>98</sub> +0.9 V<sub>97</sub> ))  
...  
	=0.1 θ<sub>100</sub> + 0.1*0.9 θ<sub>99</sub> + 0.1*(0.9)<sup>2</sup> θ<sub>98</sub> ...  

- V<sub>θ</sub> = **0 으로 두고**  
 다음 날이 되어 새로운 값(**θ<sub>T</sub>**) 이 **생성**되면  
 V<sub>θ</sub> = β V<sub>θ</sub> + (1-β) θ<sub>T</sub> 해서 **V<sub>θ</sub>를 업데이트**  
 -> 계속 업데이트가 되며 마지막에 구한 값에 **덮어쓰기** 때문에 메모리 차지가 적다 = **효율성**  
 -> 그냥 10일치를 더하고 **평균**내고 하는 것들이 훨씬 **정확**하지만  
 그러면 수치를 저장하고, 계산하는 메모리도 들고, 복잡하고 **부담**이 생기니까  
 새로운 데이터로 계속 업데이트해서 계산과 메모리 측면에서 **효율성을 높이는** 작업에 **가중 평균**이 필요하다


- **bias correction (바이어스 수정)**

  V<sub>0</sub> = 0 으로 초기화하면 초기단계에서 부정확한, **아주 작은 추정치**가 생길 수 있음  
  V<sub>1</sub> = β * 0 + (1-β) θ<sub>1</sub>  
  (β = 0.98의 경우)  = 0.02 θ<sub>1</sub> 가 되기 때문에 θ<sub>1</sub>에 비해 터무니없이 **작다**.  

  그래서 편향보정이라고 **bias correction** 을 하는데  
  그 공식은 V<sub>t</sub> = V<sub>t</sub> / (1-β<sup>t</sup>)  
  = V<sub>2</sub> = V<sub>2</sub> / (1- 0.98<sup>2</sup>) 라서 조금 더 나아진다(?)

  bias correction 은 초기 단계에서 더 나은 추정치를 얻게 도와주지만,  
  대부분 실제 머신러닝에서는 앞에도 데이터가 많아서 잘 안쓰고,  
  **초기 단계에 보다 정확한 추정치가 필요할 때** 사용!!
