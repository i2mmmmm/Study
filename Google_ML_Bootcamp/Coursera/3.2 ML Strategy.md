## 3.2 ML Strategy(2)

### 1. Error Analysis

- 에러 분석은 학습 알고리즘이 인간의 성능에 도달하지 못했을 때, 알고리즘이 발생시키는 **오류를 수동으로 검토**하여 **개선** 방향을 찾는 방법
- ex)  
  고양이 분류기가 90% 정확도 = **10% 오류율**을 가지고 있다.  
  -> 알고리즘이 강아지를 고양이로 잘못 분류하는 경우를 발견  
  -> 강아지 문제에 집중하여 알고리즘을 개선할지 고민

  100개의 잘못 분류된 dev set - **수동 검토**  
  -> 잘못 분류된 예제 중 5%가 강아지라면, 강아지 문제를 완벽히 해결하면 오류율은 10% -> 9.5% = **0.5% 줄어듬**  
  -> 잘못 분류된 예제 중 50%가 강아지라면, 강아지 문제를 해결했을 때 오류율이 10% -> 5% = **5% 줄어듬**  
  -> 특정 문제에 시간을 투자하는 것이 **얼마나 효과적일지 판단**

  - 그 외에 큰 고양이류 (사자, 치타 등) 분류의 오류나 흐릿한 이미지 분류 오류 등 다양한 문제가 있을 수도  
    -> 그럴 땐 표로 정리해보기  
    -> 어떤 문제의 비율이 높은지 보고 **어느 문제에 집중해야 하는지 판단!**  
    -> 이 과정을 통해 **시간과 자원을 효율적으로 배분**

### 2. Labeling Error

- 랜덤하게 한 두개 잘못된 라벨링은 괜찮은데, 흰강아지를 전부 고양이로 분류하는 등 **완전한 잘못된 라벨링은 문제!**
- 오류 비율 세는 표 만들었던 거에 **labeling error 열도 추가**해서 비율 같이 세보기
- 라벨링 다시 해야 할지에 대해 고민 -> dev set 에서 그 평가능력이 현저히 **개선될 수 있다면** 시간을 들여 라벨링을 새로

- 3가지 수치를 참고하면 되는데
  1. 전체적인 dev set error 수치 / ex) 10%
  2. 전체 error 중 label error / ex) 0.6%
  3. 전체 error 중 그 외 error / ex) 9.4%  
  -> 이 경우에는 그 외 error 를 손보는 게 맞고, 그렇게 error를 조정해서  
     2% / 0.6% / 1.4% 가 되면 label error 를 보는 게 맞다

- **dev set 의 의미**는 분류기 A, B 중에 어떤 것을 고를지 **선택**할 수 있도록 **도움**을 주는 것  
  근데 A error = 2.1% / B error = 1.9% 이면 label error 0.6% 가 영향력이 크니까 고쳐야만 함

- 그럼 어떻게 고칠까
  - Guideline
    1. 어떤 프로세스에 적용하던 **dev set / test set 동시 적용**  
       두 set 이 왜 같은 분포에서 와야하는지, 타겟이 같아야 하는 이야기를 한 적이 있음  
       -> **dev set 에서 무언가 고치려면 test set 에서도 똑같은 절차를 적용**

    2. 알고리즘이 맞췄던 것과 틀렸던 것의 예시를 살펴보기  
       -> 틀렸던 것만 보고 고치면 알고리즘에 더 많은 편향 추정값과 오류가 남을지도  
       -> 어려운 방법 -> 잘만들어진 분류기는 맞추는 경우가 훨씬 많아서

    3. 저 라벨들을 dev set, test set 고칠 경우,
       동일 절차를 **train set** 에 적용**할 수도**, 하지 **않을 수도**  
       train set 라벨 수정은 중요하지 않을 수도


-> 생각보다도 더 많은 수작업 오류 분석과 **인간적 통찰이 시스템에 들어간다**고 생각한다  
-> 오류를 직접 보고 세는 것은 굉장히 지겹고 힘든 일. 하지만 다음 **우선순위를 결정**하는 데에 **도움**이 된다

---
### 첫번째 시스템을 빨리 만들고 반복하기!!

set up dev/test set and metric  
먼저 개발/시험 세트와 지표를 설정해야 한다는 것 = 타겟 설정


지저분하더라도 **일단 작동하는 시스템을 만들고**  
-> 그 시스템을 이용해 **편향/분산**을 분석하고  
-> **오류**를 분석하고  
-> 분석 결과를 통해 **다음 단계 우선순위를 결정**하길

---

data from webpage　　　　　　　|　　data from mobile app  
200,000 장의 고화질 고양이 사진　|　　10,000장의 실제 다루고 싶은 고양이 사진

- train/dev/test 구성을 어떻게 할 것 인가?

**option 1.** 210,000 **suffle** - 205,000 train / 2,500 dev / 2,500 test  
-> 장점 : 모두 같은 분포에서 오기에 관리가 쉽다  
-> 큰 단점 : dev 에 실제 분류에 쓸 데이터가 너무 적음  
	-> 실제 예측하고 싶은 데이터가 dev 내의 100여개 가량  
  -> **타겟이 달라지고** 웹페이지 이미지 분포 **최적화에 많은 시간** 쏟아야 함

**option 2.** 200,000_web + 5,000_app train / 2,500_app dev / 2,500_app test  
-> train set 분포가 다르다는 것이 단점이지만  
-> 장기적으로 더 좋은 성과를 가져올 것  
