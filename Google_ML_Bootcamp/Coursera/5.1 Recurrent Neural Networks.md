## 5.1 Recurrent Neural Networks (RNN)

### 1. Sequence model (시퀀스 모델)
- 순차 데이터를 다루는 모델  
  ex) 음성인식 : X-오디오 클립, Y-텍스트 문장  
  감정분석 : X-문장(시퀀스) Y-감정 분류  
  DNA 서열 분석  
  기계 번역  
  비디오 활동 인식 등등
- X(입력), Y(출력)이 모두 시퀀스일수도 하나만 시퀀스일수도  
  X,Y 같은 길이 일수도, 다른 길이 일수도

- 표기법  
  ![image](https://github.com/user-attachments/assets/564b814f-3e23-4286-ba97-c92749a06d13)  
  입력 : X, 출력 : Y  
  X<sup>(i)⟨t⟩</sup> : i번째 샘플의 시퀀스에서 t번째 단어.

- Vocabulary 를 10000개의 단어로 구성하고 각각 고유한 벡터를 주면, 한 문장을 one-hot vector 로 표현할 수 있다  
  ![image](https://github.com/user-attachments/assets/c0f68eee-cf19-4313-995b-26b3622d0557)  
  없는 단어는 : UNK(Unknown Token)



### 2. RNN

- 기존 신경망의 문제점 : 문장 길이 달라 -> 모든 입력 출력 길이 같지 않음  
  teddy 가 사람이름 teddy 인지, teddy bear의 teddy 인지 같은 위치에 있어도 해석이 다를 수 있음
- RNN 은 순차적으로 데이터(텍스트) 처리  
  이전 단계 정보 -> 다음 단계에 전달 학습 반영  
  ![image](https://github.com/user-attachments/assets/f454a5a8-6c7d-43e7-a816-27b8f08e39f6)


- W<sub>ax</sub> : 입력 x 에서 활성화 a 로 가중치  
  W<sub>aa</sub> : 이전 활성화 a 에서 다음 활성화 a 로 가중치  
  W<sub>ay</sub>: 활성화 a 에서 출력 y 로 가중치

- 수식  
  ![image](https://github.com/user-attachments/assets/3d5c46ed-5cf4-417e-aa7f-51356ec868fc)  
  단순화를 위해 W<sub>a</sub> = [W<sub>aa</sub>,W<sub>ax</sub>] 로 병합하여 처리
