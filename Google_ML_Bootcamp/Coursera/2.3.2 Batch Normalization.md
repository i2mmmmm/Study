## 2.3.2 Batch Normalization

1. batch normalization
   - 배치 정규화의 중요성  
     하이퍼파라미터 검색을 쉽게, 신경망은 더 견고하게  
     마치 입력층에서 정규화를 통해 빠른 훈련이 가능하게 하듯이, 은닉층에 하는 것  
     - 정규화  
     ![image](https://github.com/user-attachments/assets/ccb53c27-34d5-41a9-806d-06a115a816e0)

   - 배치 정규화의 효과
     - 입력 특성 X를 평균 0, 분산 1로 정규화하면 학습 속도 빨라짐
     - 입력 피처 x를 정규화하여 학습을 돕는 것처럼, 숨겨진 층의 z 값을 정규화하여 각 층의 학습을 돕는다.
     - 활성화 함수 (예: sigmoid)를 사용하는 경우,  
       값들이 항상 0 주변에 몰려 있지 않도록!  
       활성화 함수의 비선형성을 최대한 활용할 수 있게
     - γ와 β 파라미터를 통해 숨겨진 유닛 값들의 평균과 분산을 조절

2. 딥러닝에 활용하기
   - **X** --w[1],b[1]--> **Z[1]** ---β[1],γ[1] batch norm---> **Z̃[1]** ----> **a[1]** = **g[1](Z̃[1])** --w[2],b[2]--> **Z[2]** -->....
     - 여기서 사용된 β는 모멘텀이나 Adam 알고리즘에서 사용되는 β와는 다름
   - batch norm parameter
     - 경사 하강법 등의 최적화 알고리즘을 사용하여 β, γ 파라미터를 업데이트
     - Adam, RMSprop, 모멘텀 등의 알고리즘으로 β, γ 업데이트 가능
       
3. mini batch norm
   - 첫 번째 미니배치에서 Z1을 계산
   - 미니배치의 평균과 분산을 사용하여 Z1을 정규화
   - 정규화된 값을 활성화 함수에 적용하여 A1을 계산
   - 두번째, 세번째 미니배치 -> 반복하여 Z2, Z3 계산하고 정규화
   - 각 미니배치에서 배치 정규화는 해당 미니배치의 데이터만을 사용하여 Z 값을 정규화
  
   - Z[l] = W[l] * a[l-1] + b[l]로 Z를 계산하지만, 배치 정규화 과정에서 b[l]은 의미가 없어지므로 제거
   - Z[l] 정규화하여 평균 0, 분산 1로 만들고, β, γ 통해 재조정
   - Z[l] 정규화하면 b[l]의미가 없어지므로, b[l] 0으로 설정하거나 제거
  
4. 공변량 이동(Covariate Shift)
   - 데이터 분포 변화
   - X에서 Y로의 매핑을 학습했을 때, X의 분포가 변하면 학습 알고리즘을 재훈련해야 하는 상황
   - **깊은 신경**망의 경우, **초기 층**의 **파라미터** 변화로 인해 **깊은 층**으로 전달되는 값이 변할 때 **공변량 이동**이 발생할 수 있다.
   - **배치 정규화**는 이러한 **공변량 이동을 줄여**, 깊은 층의 학습을 안정화시킨다.
   - 배치 정규화의 작동 방식
     - 배치 정규화 = 각 층의 활성화 값 Z를 평균 0, 분산 1로 정규화 후, 다시 β, γ를 사용해 재조정
     - 이렇게 하면 이전 층 파라미터 변화에도 Z의 평균과 분산이 일정하게 유지  
     -> 이후 층의 학습이 더 안정적이게 되고 학습 속도가 빨라짐
   - **배치 정규화**는 주로 정규화 효과보다는 **학습 속도 향상**을 위한 것
   - **미니배치** 크기가 **클수록** 노이즈가 줄어들어 **정규화 효과도 감소**

5. 실제 적용
   - train -> μ와 σ²는 미니 배치 단위로 계산
   - Z 값을 평균 0, 분산 1로 정규화하고 β와 γ를 사용하여 재조정
   - test -> 학습 중 지수 가중 이동 평균으로 추정된 μ와 σ² 사용
   - Z_norm 을 계산할 때 추정된 μ와 σ² 값을 사용하고, β와 γ는 학습된 값 사용
     - 지수 가중 이동 평균 계산 방법
       - 레이어 L, 미니 배치 X₁, X₂, ..., Xn -> 각각의 미니 배치에서 μ와 σ² 값
       - 각 미니배치에서 얻은 값을 지수 가중 이동 평균으로 누적하여 최신의 μ와 σ² 값을 추정
       - 첫 번째 미니 배치 : μ₁, 두 번째 : μ₂ ... -> 평균 계산, σ²도 마찬가지
       - test에서 정규화위해 사용될 예정
   - μ와 σ² 추정 방법에 집착할 필요는 없다, 대부분 제공되는 **기본 설정을 사용해도 무방**
  
     
- **배치 정규화**로 **효율적으로 학습**할 수 있고, **학습 속도**도 크게 **향상**시킬 수 있음  
+테스트 시에도 학습 중 얻은 **지수 가중 이동 평균**을 사용함으로 **안정적인 성능** 유지
