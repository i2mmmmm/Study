## 4.2 Deep convolutional models

### 1. Residual Networks (ResNet) 

- 깊은 신경망 훈련은 어려움
	- 기울기 **소실**(vanishing gradient), **폭발**(exploding gradient) 문제  
	  -> 해결하기 위해 한 계층 활성화를 더 **깊은 층으로 건너뛰기** 연결
- 기존 네트워크 : plain network : a<sup>[l]</sup> -> linear -> ReLU - a<sup>[l+1]</sup>-> linear -> ReLU -> a<sup>[l+2]</sup>
- Residual Networks : ResNet : a<sup>[l]</sup> ----------------------------------------> ReLU -> a<sup>[l+2]</sup>

- **잔류블럭**(residual blocks)을 많이 쌓아서 심층 신경망을 형성

- 이론과 달리 실제로는 너무 깊은 신경망을 만들면 오류(training error)가 커지고 역효과  
  -> **ResNet 사용**으로 네트워크 **깊어져도 오류** 지속적 **감소** 가능


- a<sup>[l+2]</sup> = g(z<sup>[l+2]</sup>+a<sup>[l]</sup>)  
　　= g(w<sup>[l+2]</sup>a<sup>[l+1]</sup>+b<sup>[l+2]</sup>+a<sup>[l]</sup>   
  -> w<sup>[l+1]</sup> = 0, b<sup>[l+2]</sup> = 0 이면 항등함수를 학습해버림  
  -> a<sup>[l+2]</sup> = a<sup>[l]</sup> 이 되어 추가된 층에 부정적 영향 X  
  -> 그렇기 때문에 깊어져도 기존 성능 유지 가능
  
- ResNet은 이미지 처리에서도 매우 효과적
- Harlow 논문에서 그림 발췌  
  ![image](https://github.com/user-attachments/assets/937b0a99-c302-4988-91ad-c205b3cbe3e8)
- 기본적으로 여러 개의 3x3 same convolution 레이어가 사용되며, 이를 통해 차원이 보존  
  -> ex) Conv Conv Conv pull 구조를 반복해 이미지에서 특징 추출, 마지막에 Fully Connected Layer를 사용해 Softmax로 분류

  ### 2. 1x1 convolution
-  이미지의 각 위치에서 한 채널의 값을 필터의 값과 곱하는 연산
  -> 단일 채널(ex-> 6x6x1 image)의 경우, 단순히 값을 곱하는 게 된다
  -> 다중 채널에서는 복잡한 연산

- 28x28x192 -> 28은 풀링으로 줄이는데 192라는 채널 축소 어떻게??  
  ex)  6x6x32 image -> 1x1x32 filter -> (각 위치의 32개의 값) X (필터의 32개의 값) -> ReLU 비선형성이 적용 -> **단일 값 출력**
  -> 28x28x192 image - **1x1x192 filter 를 사용해서 채널을 축소**할 수 있음

- 1x1 convolution의 **효과**
  - **채널 수**를 줄이거나 유지하거나, 늘리는 것도 가능
  - 연산량을 줄이고, 네트워크의 **복잡도**를 조절하는데 유용
    -> 그래서 Inception 네트워크와 같은 복잡한 신경망 구조를 설계하는 데 중요한 요소
  - 네트워크의 성능을 **최적화**하고, 계산 **비용을 절감**
 
### 3. Inception Network

![image](https://github.com/user-attachments/assets/a89f0e2f-d1a2-46ef-bf22-b12b849a1ea1)

- inception network란 여러 가지 필터 크기와 풀링 레이어를 **동시에 사용**해 더 **복잡한 구조**를 만드는 것ㅇ_ㅇ
- 위의 예시에서도 1x1, 3x3, 5x5 컨볼루션 필터, max-pooling 레이어 사용해서 각각 다른 출력 크기로 만들어 합침
- 하지만 이 과정에서 **비용**이 무지하게 **증가** -> 28x28x192 input에 5x5 필터 32개 사용하면 최소 **1억 2천만**번 곱셈해야하는...
  - 이 때 이용하는 게 **1x1 convolution**  
![image](https://github.com/user-attachments/assets/ec7648f7-e57b-4378-ad25-e2e9e87ea0e3)  
- 28x28x192 -> 1x1 conv filter 가 16개  
  각 필터의 차원(dimension)은 1x1x192 = 2.4M = 첫번째 convolution layer의 비용
- -> 28x28x16 -> 5x5 conv filter 가 32개  
  28x28x32x5x5x16 = 10.0M = 두번째 convolution layer의 비용

-> 그럼 총 곱셈을 12.4M 번 만큼 해야함 원래 비용은 120M에 달했는데 거의 **1/10**이 되는 것 


- inception module  
  ![image](https://github.com/user-attachments/assets/2e07d68e-cb23-444c-a5e7-6b3ffcb77e4c)

- inception network
  - inception module을 여러번 쌓아서 만드는 네트워크
  ![image](https://github.com/user-attachments/assets/cb21dfb0-2d80-4184-8410-589df77244c5)

