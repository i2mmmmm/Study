## 2.1 Practical aspects of Deep Learning

- 학습목표 
하이퍼파라미터 튜닝  
데이터 설정 방법  
최적화 알고리즘  
-> 실용적인 신경망 구축에 대해 배우자

### 1. train/dev/test set 설정

먼저 데이터 셋을 보면  
Data [ training set | Hold-ourt Cross validation set = development set (dev) | test set ]  
이렇게 나눌 수 있고,  
train set 을 바탕으로 **dev set을 테스트**해보고 그걸 기반으로 가장 **좋은 모델을 선정해 test 셋**에 모델을 적용하는 것  
60 / 20 / 20 정도로 하는게 과거 모범 사례 느낌  
Bigdata 시대에는 train set 자체가 크고 그 중에 작은 일부를 예측해야하는 경우가 늘고 있다.  
ex) train 1,000,000 으로 test dev 각각 10,000이라면, 98%로 1% val, 1% test 예측하는 정도

### 2. 바이어스와 분산

![image](https://github.com/i2mmmmm/Study/assets/106386971/b6166e77-b64e-4081-84ee-e72cf56058a4)

high bias -> underfitting  
high variance -> overfitting

train set error = 1% / dev set error = 11% -> high variance  
  -> train set에 과적합(overfitting)
  
train set error = 11% / dev set error = 16% -> high bias  
  -> 모델이 데이터 패턴을 파악하지 못한 상태 (underfitting)

train set error = 15% / dev set error = 30% -> high bias / high variance **[최악]**  
  -> 과적합에 패턴 파악도 못한 (overfitting and underfitting)

train set error = 0.5% / dev set error = 1% -> low bias / low variance  **[BEST]**  

bayes error = 데이터의 **본질적인 불확실성** 때문에 존재하는 이론적 **한계**  
  -> 만약 bayes error = 0.5% 라고 한다면, 어떤 모델을 사용해도 0.5%의 오류가 발생한다는 의미  

---

  2.1. high bias or high variance 인지 여부에 따라 시도해야 하는 항목이 다르다.  
  training / dev set 으로 먼저 확인하고 진단한다.  
  그 다음 시도할 항목의 적절한 하위 집단을 선택한다.  
  실제 **high bias** 인 경우, 더 많은 훈련데이터를 얻는 것은 도움이 되지 않는다. 적어도 가장 효율적인 방법은 아니다.
  
  2.2. 머신러닝 초기에는 바이어스 분산 트레이드 오프 라는 것에 대한 논의가 많았다. bias variance tradeoff  
  시도할 수 있는 방법 중 바이어스를 늘리면서 분산을 줄이거나 / 바이어스를 늘리면서 분산을 줄이거나 / 방법이 이런 것 뿐이었고  
  빅데이터 시대가 열리며 더 많은 데이터를 계속 얻는 방법이 생겼고, 그 방법을 사용하면 분산 손상을 막으면서 편향을 줄일 수 있다.  
  
정규화 - 분산을 낮추는 또 다른 유용한 작업 - 다음 시간에...
