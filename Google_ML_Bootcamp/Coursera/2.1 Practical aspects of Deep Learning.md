## 2.1 Practical aspects of Deep Learning

- 학습목표 
하이퍼파라미터 튜닝  
데이터 설정 방법  
최적화 알고리즘  
-> 실용적인 신경망 구축에 대해 배우자

1. train/dev/test set 설정

먼저 데이터 셋을 보면  
Data [ training set | Hold-ourt Cross validation set = development set (dev) | test set ]  
이렇게 나눌 수 있고,  
train set 을 바탕으로 **dev set을 테스트**해보고 그걸 기반으로 가장 **좋은 모델을 선정해 test 셋**에 모델을 적용하는 것  
60 / 20 / 20 정도로 하는게 과거 모범 사례 느낌  
Bigdata 시대에는 train set 자체가 크고 그 중에 작은 일부를 예측해야하는 경우가 늘고 있다.  
ex) train 1,000,000 으로 test dev 각각 10,000이라면, 98%로 1% val, 1% test 예측하는 정도

2. 바이어스와 분산

![image](https://github.com/i2mmmmm/Study/assets/106386971/b6166e77-b64e-4081-84ee-e72cf56058a4)

high bias -> underfitting  
high variance -> overfitting

train set error = 1% / dev set error = 11% -> high variance  
train set error = 11% / dev set error = 16% -> high bias  
train set error = 15% / dev set error = 30% -> high bias / high variance **최악**  
train set error = 0.5% / dev set error = 1% -> low bias / low variance  **best**

bayes error

  2.1. high bias or high variance 인지 여부에 따라 시도해야 하는 항목이 다르다.
training dev set 으로 먼저 확인하고 진단한다.
그 다음 시도할 항목의 적절한 하위 집단을 선택한다
실제 high bias 인 경우,
더 많은 훈련데이터를 얻는 것은 도움이 되지 않는다. 적어도 가장 효율적인 방법은 아니다.
  2.2. 머신러닝 초기에는 바이어스 분산 트레이드 오프 라는 것에 대한 논의가 많았다. bias variance tradeoff
시도할 수 있는 방법 중 바이어스를 늘리면서 분산을 줄이거나 바이어스를 늘리면서 분산을 줄이거나 방법이 이런 것뿐이었고
빅데이터 시대가 열리며 더 많은 데이터를 계속 얻는 방법이 생겼고, 그 방법을 사용하면 분산 손상을 막으면서 편향을 줄일 수 있다.
아니면 바이어스 손상없이 분산을 줄이거나...

이게 딥러닝 지도학습이 유용한 큰 이유 중 하나이다. 바이어스와 분산의 균형을 맞추는 것보다 더 유용한 일

정규화 - 분산을 낮추는 유용한 작업 - 다음 시간에...
