## 3.2 ML Strategy

### 3. train-dev set

- training error 1% / dev error 10%
1. 알고리즘이 train set 에서는 데이터를 봤지만 dev set 에서는 아니었다는 것
2. dev set 데이터 분포가 다르다는 것

- 해결하기 위해 하나의 set을 더 만들어보자
  - training-dev set : same distribution as training set, but not use for training  
    -> training set 의 부분집합 = train set 과 동일 분포

- train / dev / test　　||||　　train / train_dev / dev / test

- ex)  
train error **1%**
train-dev error **9%**  
dev error **10%**  
-> train, train-dev 두 set은 같은 분포를 가진 데이터인데 이렇게 error 차이가 있다는 건  
-> 분산의 문제가 있음

train error **1%**  
train-dev error **1.5%**  
dev error **10%**  
-> 처음보는 dev set을 보고 에러 급상승
-> **데이터 불일치** 문제 (train, dev 사이의)

human error **0%**  
train error **10%**  
train-dev error **11%**  
dev error **12%**  
-> 편향 문제 (회피가능 편향 높음) = **높은 편향** 설정

human error **0%**  
train error **10%**  
train-dev error **11%**  
dev error **20%**  
-> 분산은 작지만 회피가능 **편향**은 높고, **데이터 불일치** 문제도 높음

-> dev error / test error 차이가 크면 **dev set 과적합** 정도도 알 수 있음
-> 그러면 더 **큰 dev set**을 찾아야 함 

human error **4%**  
train error **7%**  
train-dev error **10%**  
dev error **6%**  
test error **6%**  
-> 음성 인식에서 **dev set 이 train set 보다 쉬우면** 간혹 이런 경우도 있음  
ex) 다양한 대화를 test set 으로 이용했는데, dev set은 길묻기 위치묻기 같은 차량 내 음성일 경우

### 4. 데이터 불일치 문제 해결
- 수동 오류 분석을 해보자
- dev set / test set 의 차이를 알아보자
- train, dev set 을 비슷하게 하기 위해 인공 데이터 통합을 해보자
  - ex) 그냥 말하는 소리 + car noise 소리 합성  
    차에서 녹음된 것 같은 소리로 만들어 data로 활용  
    -> 이 때 문제는 10,000 시간짜리 대화 소리와 1시간 짜리 차량 노이즈 소리를 합성하면 차량 소음에 **과적합할 위험**  
    -> 수동 오류 분석 시 사람 귀로는 구별이 어려워서 조심해야 하는 문제

- **문제가 생기면**
  - training set , dev set 어떻게 다를 수 있는지
  - dev set 과 비슷한 training set data를 어떻게 더 얻을 수 있는지
  - 인공 데이터 합성 시 너무 일부에서 시뮬레이션하고 있지 않은지

### 5. transfer learning 전이학습
- 딥러닝의 큰 장점
- 이미 개발한 모델을 다른 데에도 적용시키는 것
- 모델에서 마지막 결과값 레이어 삭제 - 마지막 레이어에 준 가중치도 삭제  
  그 전 가중치한 세트에서 무작위 초기화해 새 y_hat 생성  
  ![image](https://github.com/user-attachments/assets/04d631be-9c59-4e97-8097-710bf1693ff4)  
  - 새 데이터가 별로 없는 경우 - **마지막 레이어의 가중치**만 다시 훈련 (나머지 매개변수는 고정)
  - 데이터가 충분히 있는 경우 - 나머지 신경망에 대해 **모든 레이어** 재훈련
  - 재훈련 시킬 경우 -> pre-trainnning 가중치 나중에 업데이트(미세 조정) -> fine-tunning

- 전이학습이 유용한 경우는 (A 학습 -> B) 3가지 모두 충족
1. **같은 입력값** X를 가진 경우 ( 이미지 - 이미지 / 음성 - 음성 )
2. B 보다 **A** 작업의 **데이터**가 훨씬 더 **많을** 때 ( = B 데이터가 적은데 성능을 높이고 싶을 때 )
3. A 작업의 저수준 **특성**이 B 작업 학습에 **도움이 될거**라 판단할 때
