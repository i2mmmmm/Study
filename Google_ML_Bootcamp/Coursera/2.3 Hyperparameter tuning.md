## 2.3 Hyperparameter tuning

### 1. Hyperparameter tuning Guideline  
1. 학습률(learning rate) α : **가장 중요한** 하이퍼파라미터, 다른 것보다 우선적으로 튜닝  
2. 모멘텀 값 β : **0.9**가 좋은 기본값, 필요에 따라 튜닝
3. Adam 에서 하이퍼파라미터 β_1, β_2, ε : **0.9, 0.999, 10<sup>-8</sup>**을 사용, 튜닝 잘 안함
4. layers : 학습률 감소와 함께 중요한 요소 중 하나
5. hidden units : 모델 성능에 영향을 미칠 수 있음
6. learning rate decay : 레이어 층의 수와 함께 중요한 요소 중 하나
7. mini-batch size : 최적화 알고리즘 효율성을 위해 튜닝

- 샘플링 방법
  - 격자(grid search) : 기존 방식  
    하이퍼파라미터 2가지라면 격자무늬로 같은 간격 5x5 해서 25개 포인트 샘플링  
  - 랜덤(random search) : 최근 딥러닝에서 **추천**  
    만약 두가지가 α, ε이라고 하면 ε보다 α가 훨씬 중요한데  
    격자에서는 α 5개 값을 보는 거고, 랜덤에서는 α 25개 값을 보는 거니까  
    -> 넓은 범위에 대해 **랜덤**하게 찾고 좋은 성능을 보이는 영역에서 **밀도있게 샘플링**

### 2. Hyperparameter tuning sampling
- 그냥 랜덤이 아니라 적절한 척도를 두고 범주 안에서 랜덤한 것이 효율적이다
- 은닉 유닛 수(n[l]): 50에서 100 사이에서 무작위로 샘플링
- 신경망 층 수(L): 2에서 4 사이에서 균일하게 무작위 샘플링 또는 그리드 검색 사용.  
  이러한 경우, 균일하게 무작위 샘플링이 합리적일 수 있다.
- α (로그 스케일링 이용)  
  r = -4 * np.random.rand() / α = 10<sup>r</sup> -> 0.1, 0.01, 0.001, 0.0001
- β (로그 스케일링 이용)  
  r = -3 ~ -1 균일 샘플링 / 1 - β = 10<sup>r</sup> -> 0.9, 0.99, 0.999

- 오래 연구한다면 최소 몇달에 한번은 하이퍼파라미터 설정을 정기적으로 다시 평가해보는 것이 좋다.
- Pandas approach
  - 데이터는 많지만 계산 **자원이 부족**할 때 사용
  - **하나의 모델**을 관리하며 매일 학습 곡선을 모니터링하고 **하이퍼파라미터를 조금씩 조정**해 관찰한다.
- Caviar approach
  - **많은 자원**을 이용할 수 있을 때 사용
  - 여러 모델을 **동시**에 실행, 다양한 설정을 실험할 수 있어 효율적이다.
  - 리소스가 충분하다면 역시 이 방법을 **추천**


