## 1.2 신경망 (로지스틱 회귀분석)


### 0. 신경망 프로그래밍 기초
신경망 구현 -> m개 train set, for 문 처리, 순전파, 역전파

### 1. 로지스틱 회귀분석 => 이진분류 (Binary Classification)  
   - 표본의 수 : m  
   - x는 x차원 특징벡터  
   - y는 0,1 중 하나의 값  
   - {(x1,y1),(x2,y2), ... ,(xm,ym)}

### 2. 로지스틱 회귀분석
   - **지도학습**에서 y(결과)가 **0 또는 1** 인 경우에 사용하는 학습 알고리즘
   - X : 사진 -> y (결과값 = 확률) = P(y=1|X)
   - parameter : W ∈ ℝ<sup>n<sub>x</sub></sup> (n차원 벡터), b ∈ ℝ (실수)
   - output : ŷ = W<sup>T</sup> X + b  
     0 ≤ ŷ ≤ 1 이어야 하는데 이렇게 되면 W<sup>T</sup> X + b 는 1보다 크거나 음수일 수 있어서  
     좋은 함수가 아니며, 확률에 맞지 않는다.
     -> 그래서 출력에 **시그모이드 함수(σ)** 를 사용
     
     - 시그모이드 함수  
       ![image](https://github.com/i2mmmmm/Study/assets/106386971/8b29ed22-6482-4c60-8a18-73b8db5b8de7)
       ![image](https://github.com/i2mmmmm/Study/assets/106386971/8c7e518f-bcca-4d33-b5b0-32d19cc9428c)
     - x 값이 커질수록 e<sup>-z</sup> ≈ 0 -> σ(x) ≈ 1
     - x 값이 작아질수록 e<sup>-z</sup> 값 커지고 -> σ(x) ≈ 0
   - 그래서 0 ≤ σ(x) ≤ 1 이 가능해지도록, **ŷ = σ(W<sup>T</sup> X + b)** 이렇게!
   - **로지스틱 회귀 분석의 목표**는 parameter(매개변수) W 와 b 를 학습해 **ŷ = 1 일 가능성**에 대한 좋은 추정치가 되도록 하는 것
     
